# Halliciguard: LLM Agents to Fact Check and Guard Against Hallucinations of Other LLMs

A set of prompts to use LLMs to fact check and detect hallucinations in other LLMs.

Agent Prompts folder -- contains usable prompts for checker agents (can be ported to any agentic framework)

Demo: python run.py 
  * Uses an agent to make some true and some false claims
  * Run the checker and report an accuracy
